{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 24 02:56:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 45%   61C    P2   104W / 260W |   3845MiB / 11019MiB |     48%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-24 02:56:40--  https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 196205945 (187M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth’\n",
      "\n",
      "pspnet_r50-d8_512x1 100%[===================>] 187.12M  7.79MB/s    in 24s     \n",
      "\n",
      "2022-03-24 02:57:05 (7.74 MB/s) - ‘checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth’ saved [196205945/196205945]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!wget https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth -P checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../data/dataset1/'\n",
    "train_img_dir = 'train_img'\n",
    "train_ann_dir = 'train_label'\n",
    "\n",
    "test_img_dir = 'train_img'\n",
    "test_ann_dir = 'train_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "img = mmcv.imread('../data/dataset1/train_img/10631_2019-02-08-00-51-44_Borer_21_TopbarRight.jpg')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# define class and plaette for better visualization\n",
    "classes = ('no_seam','seam')\n",
    "palette = [[0,0,0],[255,255,255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "def format_mask_white(path):\n",
    "    dirs = os.listdir(path)\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            im_rgb = im.convert(mode='RGB')\n",
    "            data = np.copy(np.asarray(im_rgb))\n",
    "            data[data==1] = 255\n",
    "            img = Image.fromarray(data, 'RGB')\n",
    "            img.save(path+item)   \n",
    "        \n",
    "# format_mask_white(\"../data/dataset1/train_label/\")\n",
    "# format_mask_white(\"../data/dataset1/test_label/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the segmentation map\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline \n",
    "\n",
    "im = Image.open('../data/dataset1/train_label/10631_2019-02-08-00-51-44_Borer_21_TopbarRight.png')\n",
    "im_rgb = im.convert(mode='RGB')\n",
    "data = np.copy(np.asarray(im_rgb))\n",
    "data[data==1] = 255\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "plt.imshow(img)\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(len(classes))]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/val set randomly\n",
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, train_ann_dir), suffix='.png')]\n",
    "\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "  f.writelines(line + '\\n' for line in filename_list)\n",
    "   \n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, test_ann_dir), suffix='.png')]\n",
    "\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "  f.writelines(line + '\\n' for line in filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ClaySeamDataset(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('../mmsegmentation/configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained='open-mmlab://resnet50_v1c',\n",
      "    backbone=dict(\n",
      "        type='ResNetV1c',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        dilations=(1, 1, 2, 4),\n",
      "        strides=(1, 2, 1, 1),\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        contract_dilation=True),\n",
      "    decode_head=dict(\n",
      "        type='PSPHead',\n",
      "        in_channels=2048,\n",
      "        in_index=3,\n",
      "        channels=512,\n",
      "        pool_scales=(1, 2, 3, 6),\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=2,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=1024,\n",
      "        in_index=2,\n",
      "        channels=256,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=2,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'ClaySeamDataset'\n",
      "data_root = '../data/dataset1/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (256, 256)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(320, 240),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=8,\n",
      "    workers_per_gpu=8,\n",
      "    train=dict(\n",
      "        type='ClaySeamDataset',\n",
      "        data_root='../data/dataset1/',\n",
      "        img_dir='train_img',\n",
      "        ann_dir='train_label',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
      "            dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ],\n",
      "        split='splits/train.txt'),\n",
      "    val=dict(\n",
      "        type='ClaySeamDataset',\n",
      "        data_root='../data/dataset1/',\n",
      "        img_dir='train_img',\n",
      "        ann_dir='train_label',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(320, 240),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'),\n",
      "    test=dict(\n",
      "        type='ClaySeamDataset',\n",
      "        data_root='../data/dataset1/',\n",
      "        img_dir='train_img',\n",
      "        ann_dir='train_label',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(320, 240),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'))\n",
      "log_config = dict(\n",
      "    interval=10, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=200)\n",
      "checkpoint_config = dict(by_epoch=False, interval=200)\n",
      "evaluation = dict(interval=200, metric='mIoU', pre_eval=True)\n",
      "work_dir = './work_dirs/tutorial'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 2\n",
    "cfg.model.auxiliary_head.num_classes = 2\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'ClaySeamDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.data.samples_per_gpu = 8\n",
    "cfg.data.workers_per_gpu=8\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (256, 256)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(320, 240),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = train_img_dir\n",
    "cfg.data.train.ann_dir = train_ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = test_img_dir\n",
    "cfg.data.val.ann_dir = test_ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = test_img_dir\n",
    "cfg.data.test.ann_dir = test_ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/tutorial'\n",
    "\n",
    "cfg.runner.max_iters = 200\n",
    "cfg.log_config.interval = 10\n",
    "cfg.evaluation.interval = 200\n",
    "cfg.checkpoint_config.interval = 200\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mmcv/utils/misc.py:324: UserWarning: \"flip_ratio\" is deprecated in `RandomFlip.__init__`, please use \"prob\" instead\n",
      "  f'\"{src_arg_name}\" is deprecated in '\n",
      "2022-03-24 02:57:10,647 - mmseg - INFO - Loaded 3872 images\n",
      "/usr/src/research/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "2022-03-24 02:57:13,116 - mmseg - INFO - Loaded 3872 images\n",
      "2022-03-24 02:57:13,117 - mmseg - INFO - load checkpoint from checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n",
      "2022-03-24 02:57:13,118 - mmseg - INFO - Use load_from_local loader\n",
      "2022-03-24 02:57:13,243 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([19, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
      "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([19, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
      "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "2022-03-24 02:57:13,250 - mmseg - INFO - Start running, host: root@ee56ff105a27, work_dir: /usr/src/research/scripts/work_dirs/tutorial\n",
      "2022-03-24 02:57:13,251 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-03-24 02:57:13,251 - mmseg - INFO - workflow: [('train', 1)], max: 200 iters\n",
      "2022-03-24 02:57:16,899 - mmseg - INFO - Iter [10/200]\tlr: 9.598e-03, eta: 0:01:04, time: 0.339, data_time: 0.011, memory: 3768, decode.loss_ce: 0.4416, decode.acc_seg: 69.8887, aux.loss_ce: 0.1844, aux.acc_seg: 71.2282, loss: 0.6261\n",
      "2022-03-24 02:57:19,765 - mmseg - INFO - Iter [20/200]\tlr: 9.149e-03, eta: 0:00:56, time: 0.286, data_time: 0.005, memory: 3768, decode.loss_ce: 0.3023, decode.acc_seg: 77.7567, aux.loss_ce: 0.1331, aux.acc_seg: 77.0110, loss: 0.4354\n",
      "2022-03-24 02:57:22,739 - mmseg - INFO - Iter [30/200]\tlr: 8.698e-03, eta: 0:00:52, time: 0.297, data_time: 0.004, memory: 3768, decode.loss_ce: 0.2575, decode.acc_seg: 81.2178, aux.loss_ce: 0.1054, aux.acc_seg: 82.7274, loss: 0.3629\n",
      "2022-03-24 02:57:25,692 - mmseg - INFO - Iter [40/200]\tlr: 8.244e-03, eta: 0:00:48, time: 0.296, data_time: 0.005, memory: 3768, decode.loss_ce: 0.2465, decode.acc_seg: 85.5700, aux.loss_ce: 0.0991, aux.acc_seg: 86.6335, loss: 0.3456\n",
      "2022-03-24 02:57:28,671 - mmseg - INFO - Iter [50/200]\tlr: 7.788e-03, eta: 0:00:45, time: 0.298, data_time: 0.005, memory: 3768, decode.loss_ce: 0.2327, decode.acc_seg: 86.7559, aux.loss_ce: 0.0928, aux.acc_seg: 86.7545, loss: 0.3255\n",
      "2022-03-24 02:57:31,555 - mmseg - INFO - Iter [60/200]\tlr: 7.328e-03, eta: 0:00:42, time: 0.288, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1777, decode.acc_seg: 89.5232, aux.loss_ce: 0.0746, aux.acc_seg: 89.3413, loss: 0.2524\n",
      "2022-03-24 02:57:34,498 - mmseg - INFO - Iter [70/200]\tlr: 6.865e-03, eta: 0:00:38, time: 0.295, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1725, decode.acc_seg: 90.4404, aux.loss_ce: 0.0724, aux.acc_seg: 89.9857, loss: 0.2449\n",
      "2022-03-24 02:57:37,497 - mmseg - INFO - Iter [80/200]\tlr: 6.398e-03, eta: 0:00:35, time: 0.300, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1844, decode.acc_seg: 89.4865, aux.loss_ce: 0.0761, aux.acc_seg: 89.5483, loss: 0.2606\n",
      "2022-03-24 02:57:40,327 - mmseg - INFO - Iter [90/200]\tlr: 5.928e-03, eta: 0:00:32, time: 0.283, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1572, decode.acc_seg: 90.5991, aux.loss_ce: 0.0639, aux.acc_seg: 90.5359, loss: 0.2211\n",
      "2022-03-24 02:57:43,221 - mmseg - INFO - Iter [100/200]\tlr: 5.453e-03, eta: 0:00:29, time: 0.290, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1754, decode.acc_seg: 89.7619, aux.loss_ce: 0.0726, aux.acc_seg: 89.6472, loss: 0.2480\n",
      "2022-03-24 02:57:46,045 - mmseg - INFO - Iter [110/200]\tlr: 4.974e-03, eta: 0:00:26, time: 0.282, data_time: 0.004, memory: 3768, decode.loss_ce: 0.1909, decode.acc_seg: 88.9982, aux.loss_ce: 0.0784, aux.acc_seg: 89.1497, loss: 0.2694\n",
      "2022-03-24 02:57:49,095 - mmseg - INFO - Iter [120/200]\tlr: 4.489e-03, eta: 0:00:23, time: 0.303, data_time: 0.004, memory: 3768, decode.loss_ce: 0.1621, decode.acc_seg: 90.8144, aux.loss_ce: 0.0670, aux.acc_seg: 90.7134, loss: 0.2291\n",
      "2022-03-24 02:57:51,941 - mmseg - INFO - Iter [130/200]\tlr: 3.998e-03, eta: 0:00:20, time: 0.287, data_time: 0.007, memory: 3768, decode.loss_ce: 0.1673, decode.acc_seg: 90.1354, aux.loss_ce: 0.0704, aux.acc_seg: 89.8555, loss: 0.2377\n",
      "2022-03-24 02:57:54,787 - mmseg - INFO - Iter [140/200]\tlr: 3.500e-03, eta: 0:00:17, time: 0.284, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1663, decode.acc_seg: 90.9926, aux.loss_ce: 0.0710, aux.acc_seg: 90.6260, loss: 0.2373\n",
      "2022-03-24 02:57:57,784 - mmseg - INFO - Iter [150/200]\tlr: 2.994e-03, eta: 0:00:14, time: 0.300, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1680, decode.acc_seg: 90.5301, aux.loss_ce: 0.0717, aux.acc_seg: 90.0908, loss: 0.2397\n",
      "2022-03-24 02:58:00,790 - mmseg - INFO - Iter [160/200]\tlr: 2.478e-03, eta: 0:00:11, time: 0.299, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1688, decode.acc_seg: 90.1886, aux.loss_ce: 0.0703, aux.acc_seg: 89.7433, loss: 0.2391\n",
      "2022-03-24 02:58:03,745 - mmseg - INFO - Iter [170/200]\tlr: 1.949e-03, eta: 0:00:08, time: 0.297, data_time: 0.006, memory: 3768, decode.loss_ce: 0.1600, decode.acc_seg: 90.8576, aux.loss_ce: 0.0661, aux.acc_seg: 90.7341, loss: 0.2261\n",
      "2022-03-24 02:58:06,763 - mmseg - INFO - Iter [180/200]\tlr: 1.402e-03, eta: 0:00:05, time: 0.302, data_time: 0.004, memory: 3768, decode.loss_ce: 0.1526, decode.acc_seg: 91.1115, aux.loss_ce: 0.0642, aux.acc_seg: 90.7845, loss: 0.2168\n",
      "2022-03-24 02:58:09,592 - mmseg - INFO - Iter [190/200]\tlr: 8.277e-04, eta: 0:00:02, time: 0.282, data_time: 0.004, memory: 3768, decode.loss_ce: 0.1468, decode.acc_seg: 91.2096, aux.loss_ce: 0.0622, aux.acc_seg: 90.7564, loss: 0.2090\n",
      "2022-03-24 02:58:12,555 - mmseg - INFO - Saving checkpoint at 200 iterations\n",
      "2022-03-24 02:58:13,178 - mmseg - INFO - Iter [200/200]\tlr: 1.841e-04, eta: 0:00:00, time: 0.362, data_time: 0.005, memory: 3768, decode.loss_ce: 0.1512, decode.acc_seg: 91.2224, aux.loss_ce: 0.0648, aux.acc_seg: 90.8820, loss: 0.2159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 3872/3872, 30.7 task/s, elapsed: 126s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 03:00:19,576 - mmseg - INFO - per class results:\n",
      "2022-03-24 03:00:19,577 - mmseg - INFO - \n",
      "+---------+-------+-------+\n",
      "|  Class  |  IoU  |  Acc  |\n",
      "+---------+-------+-------+\n",
      "| no_seam | 89.56 | 94.08 |\n",
      "|   seam  |  67.5 | 81.87 |\n",
      "+---------+-------+-------+\n",
      "2022-03-24 03:00:19,578 - mmseg - INFO - Summary:\n",
      "2022-03-24 03:00:19,579 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 91.42 | 78.53 | 87.97 |\n",
      "+-------+-------+-------+\n",
      "2022-03-24 03:00:19,586 - mmseg - INFO - Iter(val) [3872]\taAcc: 0.9142, mIoU: 0.7853, mAcc: 0.8797, IoU.no_seam: 0.8956, IoU.seam: 0.6750, Acc.no_seam: 0.9408, Acc.seam: 0.8187\n"
     ]
    }
   ],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "img = mmcv.imread('../data/dataset1/train_img/10631_2019-02-08-00-51-44_Borer_21_TopbarRight.jpg')\n",
    "\n",
    "model.cfg = cfg\n",
    "result = inference_segmentor(model, img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "show_result_pyplot(model, img, result, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
